/**
 * @fileoverview Defines the core interface (IGMI) for a Generalized Mind Instance,
 * its configuration, inputs, outputs, states, and related data structures.
 * The GMI is the central cognitive engine in AgentOS.
 * @module backend/agentos/cognitive_substrate/IGMI
 */

import { IPersonaDefinition } from './personas/IPersonaDefinition';
import { IWorkingMemory } from './memory/IWorkingMemory';
import { IPromptEngine } from '../core/llm/IPromptEngine';
import { IRetrievalAugmentor } from '../rag/IRetrievalAugmentor';
import { AIModelProviderManager } from '../core/llm/providers/AIModelProviderManager';
import { IUtilityAI } from '../core/ai_utilities/IUtilityAI';
import { IToolOrchestrator } from '../tools/IToolOrchestrator'; // Ensured import
import { ModelUsage } from '../core/llm/providers/IProvider';

/**
 * Defines the possible moods a GMI can be in, influencing its behavior and responses.
 * These moods can be adapted based on interaction context or self-reflection.
 * @enum {string}
 */
export enum GMIMood {
  NEUTRAL = 'neutral',
  FOCUSED = 'focused',
  EMPATHETIC = 'empathetic',
  CURIOUS = 'curious',
  ASSERTIVE = 'assertive',
  ANALYTICAL = 'analytical',
  FRUSTRATED = 'frustrated', // Internal state, may or may not be expressed
  CREATIVE = 'creative',
  // Add more moods as the system evolves
}

/**
 * Defines the primary operational states of a GMI.
 * @enum {string}
 */
export enum GMIPrimeState {
  IDLE = 'idle', // Initial state before initialization
  INITIALIZING = 'initializing',
  READY = 'ready', // Ready to process turns
  PROCESSING = 'processing', // Actively processing a turn (could be LLM call or internal logic)
  AWAITING_TOOL_RESULT = 'awaiting_tool_result', // LLM requested tools, GMI is executing them
  REFLECTING = 'reflecting', // Performing self-reflection cycle
  ERRORED = 'errored', // Encountered a critical error, may need reset or intervention
  SHUTTING_DOWN = 'shutting_down',
  SHUTDOWN = 'shutdown',
}

/**
 * Represents the contextual information about the user interacting with the GMI.
 * This data helps the GMI tailor its responses and behavior.
 * @interface UserContext
 */
export interface UserContext {
  /** A unique identifier for the user. */
  userId: string;
  /**
   * The user's skill level related to the current domain or task.
   * @example "novice", "intermediate", "expert"
   */
  skillLevel?: string;
  /**
   * A record of user preferences that can influence GMI behavior.
   * @example { "output_format": "markdown", "verbosity": "concise" }
   */
  preferences?: Record<string, any>;
  /** A summary of past interactions with this user, potentially used for personalization. */
  pastInteractionSummary?: string;
  /**
   * Current sentiment of the user, if detectable.
   * @example "positive", "negative", "neutral"
   */
  currentSentiment?: string;
  /** Other relevant user-specific attributes. */
  [key: string]: any; // For extensibility
}

/**
 * Represents the contextual information about the task the GMI is currently handling.
 * @interface TaskContext
 */
export interface TaskContext {
  /** A unique identifier for the current task or sub-task. */
  taskId: string;
  /**
   * The domain of the current task.
   * @example "coding_python", "financial_data_analysis", "travel_planning"
   */
  domain?: string;
  /**
   * The perceived complexity of the current task.
   * @example "low", "medium", "high", "very_high"
   */
  complexity?: string;
  /** The specific goal or objective of the current task. */
  goal?: string;
  /** Current status of the task. */
  status?: 'not_started' | 'in_progress' | 'blocked' | 'requires_clarification' | 'completed' | 'failed';
  /** Detailed requirements, constraints, or input data for the task. */
  requirements?: string;
  /** Progress of the task, if measurable (e.g., 0-100). */
  progress?: number;
  /** Other relevant task-specific attributes. */
  [key: string]: any; // For extensibility
}

/**
 * Describes a request from the LLM to call a specific tool/function.
 * This structure is typically part of the LLM's response when it decides a tool is needed.
 *
 * @interface ToolCallRequest
 * @property {string} id - A unique identifier for this specific tool call instance, often generated by the LLM.
 * This ID is crucial for matching the tool call request with its corresponding result.
 * @property {string} name - The name of the function/tool to be called (e.g., "searchWeb", "getCurrentWeather").
 * This name should match one of the tools available to the GMI/LLM, corresponding to `ITool.name`.
 * @property {Record<string, any>} arguments - An object containing the arguments for the tool.
 * The LLM typically generates this as a JSON object (or a string that needs parsing into one).
 * The structure of these arguments must conform to the input schema (`ITool.inputSchema`) of the specified tool.
 */
export interface ToolCallRequest {
  id: string;
  name: string;
  arguments: Record<string, any>; // LLM usually provides this as object after parsing its own JSON string output
}

/**
 * Represents the result of a tool execution, structured to be sent back to the LLM.
 *
 * @interface ToolCallResult
 * @property {string} toolCallId - The ID from the original `ToolCallRequest` this result corresponds to.
 * This allows the LLM to correlate the result with its request.
 * @property {string} toolName - The name of the tool that was executed. Matches `ToolCallRequest.name`.
 * @property {any} output - The output data from the tool execution.
 * For the LLM, this is typically a string (e.g., JSON.stringify(actualToolOutput) or a descriptive text).
 * The actual type depends on what the tool produces and how it's best represented for the LLM.
 * @property {boolean} [isError=false] - Flag indicating if an error occurred during the tool's execution.
 * @property {any} [errorDetails] - If `isError` is true, this field provides details about the error.
 * This could be an error message string or a more structured error object.
 */
export interface ToolCallResult {
  toolCallId: string;
  toolName: string;
  output: any; // For LLM, often stringified JSON or descriptive text of error/success
  isError?: boolean;
  errorDetails?: any;
}

/**
 * Base configuration required to initialize a GMI instance.
 * This includes dependencies on other core AgentOS services and managers.
 *
 * @interface GMIBaseConfig
 * @property {IWorkingMemory} workingMemory - The working memory instance for this GMI.
 * @property {IPromptEngine} promptEngine - The prompt engineering engine.
 * @property {AIModelProviderManager} llmProviderManager - Manager for LLM providers.
 * @property {IUtilityAI} utilityAI - Service for auxiliary AI tasks.
 * @property {IToolOrchestrator} toolOrchestrator - The orchestrator for managing and executing tools.
 * @property {IRetrievalAugmentor} [retrievalAugmentor] - Optional RAG system.
 * @property {string} [defaultLlmProviderId] - Optional default LLM provider ID.
 * @property {string} [defaultLlmModelId] - Optional default LLM model ID.
 * @property {Record<string, any>} [customSettings] - Other custom GMI runtime settings.
 */
export interface GMIBaseConfig {
  workingMemory: IWorkingMemory;
  promptEngine: IPromptEngine;
  llmProviderManager: AIModelProviderManager;
  utilityAI: IUtilityAI;
  toolOrchestrator: IToolOrchestrator; // Integrated
  retrievalAugmentor?: IRetrievalAugmentor;
  defaultLlmProviderId?: string;
  defaultLlmModelId?: string;
  customSettings?: Record<string, any>;
}

/**
 * Defines the type of interaction or input being provided to the GMI.
 * @enum {string}
 */
export enum GMIInteractionType {
  TEXT = 'text', // User sends simple text
  MULTIMODAL_CONTENT = 'multimodal_content', // User sends complex content (e.g., text + image URLs/data)
  TOOL_RESPONSE = 'tool_response', // System provides result of a GMI-initiated tool call back to the GMI
  SYSTEM_MESSAGE = 'system_message', // System sends an advisory message or instruction to GMI
  LIFECYCLE_EVENT = 'lifecycle_event', // e.g., memory lifecycle event for GMI to react to
}

/**
 * Represents a single turn of input to the GMI.
 * @interface GMITurnInput
 */
export interface GMITurnInput {
  /** A unique identifier for this specific interaction/turn. */
  interactionId: string;
  /** The ID of the user initiating this turn. */
  userId: string;
  /** Optional: ID of the current session or conversation. */
  sessionId?: string;
  /** The type of interaction. */
  type: GMIInteractionType;
  /**
   * The primary content of the input.
   * - For `TEXT`: string.
   * - For `MULTIMODAL_CONTENT`: structured object (e.g., `[{type: 'text', text: '...'}, {type: 'image_url', image_url: '...'}]`).
   * - For `TOOL_RESPONSE`: a `ToolCallResult` object (or array if multiple tools were called in parallel by LLM).
   * - For `SYSTEM_MESSAGE`: string or structured object.
   */
  content: string | ToolCallResult | ToolCallResult[] | Record<string, any> | Array<Record<string, any>>;
  /** Timestamp of when the input was generated or received. Defaults to now if not provided. */
  timestamp?: Date;
  /** Allows overriding parts of the GMI's current UserContext for this turn. */
  userContextOverride?: Partial<UserContext>;
  /** Allows overriding parts of the GMI's current TaskContext for this turn. */
  taskContextOverride?: Partial<TaskContext>;
  /** Any additional metadata associated with this input. */
  metadata?: Record<string, any>;
}

/**
 * Defines the type of content in a `GMIOutputChunk`.
 * @enum {string}
 */
export enum GMIOutputChunkType {
  TEXT_DELTA = 'text_delta',          // A segment of a streamed text response.
  TOOL_CALL_REQUEST = 'tool_call_request', // GMI (via LLM) is requesting one or more tools to be called. The content will be ToolCallRequest[].
  // TOOL_CALL_DELTA = 'tool_call_delta', // Future: For streaming arguments of a tool call as LLM generates them.
  REASONING_STATE_UPDATE = 'reasoning_state_update', // An update on GMI's internal thought process (e.g., "Now searching RAG...").
  FINAL_RESPONSE_MARKER = 'final_response_marker', // Signals the end of a complete logical response from GMI for the current interaction.
  ERROR = 'error',                  // An error occurred during GMI processing. Content provides error details.
  SYSTEM_MESSAGE = 'system_message',  // A message from GMI/system not part of direct response (e.g., "Context saved.").
  USAGE_UPDATE = 'usage_update',      // Provides interim or final token usage information for the turn.
  LATENCY_REPORT = 'latency_report',  // Provides timing information for different stages of processing.
}

/**
 * Represents a chunk of output streamed from the GMI during turn processing.
 *
 * @interface GMIOutputChunk
 * @property {GMIOutputChunkType} type - The type of content in this chunk.
 * @property {any} content - The actual content of the chunk, its structure depends on `type`.
 * - `TEXT_DELTA`: string (the text segment).
 * - `TOOL_CALL_REQUEST`: `ToolCallRequest[]` (one or more tool calls requested by LLM).
 * - `REASONING_STATE_UPDATE`: string (description of the current reasoning state).
 * - `ERROR`: string (error message) or an object with error details.
 * - `SYSTEM_MESSAGE`: string (the system message).
 * - `USAGE_UPDATE`: `ModelUsage` object.
 * @property {string} [chunkId] - Optional unique ID for this specific chunk.
 * @property {string} interactionId - Corresponds to the `GMITurnInput.interactionId` this chunk relates to.
 * @property {Date} timestamp - When this chunk was generated.
 * @property {boolean} [isFinal=false] - If `type` is `FINAL_RESPONSE_MARKER`, this is true.
 * For `TEXT_DELTA`, true if it's the last text chunk of a sentence/paragraph, or end of LLM stream.
 * @property {string} [finishReason] - If `isFinal` is true (especially for LLM text streams), the reason for finishing (e.g., "stop", "length", "tool_calls").
 * @property {ModelUsage} [usage] - Token usage information, often provided with `TEXT_DELTA` or `FINAL_RESPONSE_MARKER`.
 * @property {any} [errorDetails] - If `type` is `ERROR`, structured details about the error.
 * @property {Record<string, any>} [metadata] - Additional metadata for this chunk.
 */
export interface GMIOutputChunk {
  type: GMIOutputChunkType;
  content: any;
  chunkId?: string;
  interactionId: string;
  timestamp: Date;
  isFinal?: boolean;
  finishReason?: string;
  usage?: ModelUsage;
  errorDetails?: any;
  metadata?: Record<string, any>;
}

/**
 * Types of entries that can appear in a GMI's reasoning trace.
 * @enum {string}
 */
export enum ReasoningEntryType {
  LIFECYCLE = 'LIFECYCLE',
  INTERACTION_START = 'INTERACTION_START',
  INTERACTION_END = 'INTERACTION_END',
  STATE_CHANGE = 'STATE_CHANGE',
  PROMPT_CONSTRUCTION_START = 'PROMPT_CONSTRUCTION_START',
  PROMPT_CONSTRUCTION_DETAIL = 'PROMPT_CONSTRUCTION_DETAIL',
  PROMPT_CONSTRUCTION_COMPLETE = 'PROMPT_CONSTRUCTION_COMPLETE',
  LLM_CALL_START = 'LLM_CALL_START',
  LLM_CALL_COMPLETE = 'LLM_CALL_COMPLETE',
  LLM_RESPONSE_CHUNK = 'LLM_RESPONSE_CHUNK',
  LLM_USAGE = 'LLM_USAGE',
  TOOL_CALL_REQUESTED = 'TOOL_CALL_REQUESTED',
  TOOL_PERMISSION_CHECK_START = 'TOOL_PERMISSION_CHECK_START',
  TOOL_PERMISSION_CHECK_RESULT = 'TOOL_PERMISSION_CHECK_RESULT',
  TOOL_ARGUMENT_VALIDATION = 'TOOL_ARGUMENT_VALIDATION',
  TOOL_EXECUTION_START = 'TOOL_EXECUTION_START',
  TOOL_EXECUTION_RESULT = 'TOOL_EXECUTION_RESULT', // Contains the ToolCallResult or summary
  RAG_QUERY_START = 'RAG_QUERY_START',
  RAG_QUERY_DETAIL = 'RAG_QUERY_DETAIL',
  RAG_QUERY_RESULT = 'RAG_QUERY_RESULT',
  RAG_INGESTION_START = 'RAG_INGESTION_START',
  RAG_INGESTION_COMPLETE = 'RAG_INGESTION_COMPLETE',
  SELF_REFLECTION_TRIGGERED = 'SELF_REFLECTION_TRIGGERED',
  SELF_REFLECTION_START = 'SELF_REFLECTION_START',
  SELF_REFLECTION_DETAIL = 'SELF_REFLECTION_DETAIL',
  SELF_REFLECTION_COMPLETE = 'SELF_REFLECTION_COMPLETE',
  MEMORY_LIFECYCLE_EVENT_RECEIVED = 'MEMORY_LIFECYCLE_EVENT_RECEIVED',
  MEMORY_LIFECYCLE_NEGOTIATION_START = 'MEMORY_LIFECYCLE_NEGOTIATION_START',
  MEMORY_LIFECYCLE_RESPONSE_SENT = 'MEMORY_LIFECYCLE_RESPONSE_SENT',
  HEALTH_CHECK_REQUESTED = 'HEALTH_CHECK_REQUESTED',
  HEALTH_CHECK_RESULT = 'HEALTH_CHECK_RESULT',
  WARNING = 'WARNING',
  ERROR = 'ERROR',
  DEBUG = 'DEBUG',
}

/**
 * A single entry in the GMI's reasoning trace, providing an auditable log of its operations.
 * @interface ReasoningTraceEntry
 */
export interface ReasoningTraceEntry {
  timestamp: Date;
  type: ReasoningEntryType;
  message: string;
  details?: Record<string, any>;
}

/**
 * The complete reasoning trace for a GMI instance or a specific turn.
 * @interface ReasoningTrace
 */
export interface ReasoningTrace {
  gmiId: string;
  personaId: string;
  turnId?: string; // Optional: Associate entries with a specific interaction turn
  entries: ReasoningTraceEntry[];
}

/**
 * Represents an event related to memory lifecycle management that the GMI needs to be aware of or act upon.
 * This event is typically emitted by a `MemoryLifecycleManager`.
 *
 * @interface MemoryLifecycleEvent
 * @property {string} eventId - Unique ID for this lifecycle event.
 * @property {Date} timestamp - When the event was generated.
 * @property {'EVICTION_PROPOSED' | 'ARCHIVAL_PROPOSED' | 'DELETION_PROPOSED' | 'SUMMARY_PROPOSED' | 'RETENTION_REVIEW_PROPOSED' | 'NOTIFICATION' | 'EVALUATION_PROPOSED'} type - The type of lifecycle event.
 * @property {string} gmiId - The ID of the GMI this event pertains to (if item is GMI-specific).
 * @property {string} [personaId] - The Persona ID if the memory item is persona-specific.
 * @property {string} itemId - The unique ID of the memory item in question.
 * @property {string} dataSourceId - The data source where the item resides (e.g., RAG collection ID).
 * @property {string} [category] - The logical category of the memory item (e.g., from `RagMemoryCategory`).
 * @property {string} itemSummary - A brief summary or description of the memory item.
 * @property {string} reason - The reason why this lifecycle event was triggered (e.g., "Exceeded retention period", "Storage quota nearing limit").
 * @property {LifecycleAction} proposedAction - The action the `MemoryLifecycleManager` proposes to take on the item.
 * @property {boolean} negotiable - True if the GMI can influence the outcome of this event (e.g., prevent deletion, propose alternative).
 * @property {Record<string, any>} [metadata] - Additional metadata related to the event or item.
 */
export interface MemoryLifecycleEvent {
  eventId: string;
  timestamp: Date;
  type: 'EVICTION_PROPOSED' | 'ARCHIVAL_PROPOSED' | 'DELETION_PROPOSED' | 'SUMMARY_PROPOSED' | 'RETENTION_REVIEW_PROPOSED' | 'NOTIFICATION' | 'EVALUATION_PROPOSED';
  gmiId: string; // Which GMI owns or is primarily associated with this memory item
  personaId?: string;
  itemId: string; // ID of the memory item (e.g., document chunk ID in RAG)
  dataSourceId: string;
  category?: string; // e.g., RagMemoryCategory
  itemSummary: string; // A human-readable summary of the item for the GMI to understand
  reason: string; // Why this event is occurring
  proposedAction: LifecycleAction; // The action the MemoryLifecycleManager wants to take
  negotiable: boolean; // Can the GMI influence this?
  metadata?: Record<string, any>;
}

/**
 * Defines the possible actions a GMI can take or that can be proposed/taken regarding a memory item.
 * This is used in `MemoryLifecycleEvent.proposedAction` and `LifecycleActionResponse.actionTaken`.
 * @enum {string}
 */
export type LifecycleAction =
  | 'ALLOW_ACTION'         // GMI allows the proposed action from MemoryLifecycleManager.
  | 'PREVENT_ACTION'       // GMI explicitly prevents the proposed action.
  | 'DELETE'               // GMI requests/confirms deletion.
  | 'ARCHIVE'              // GMI requests/confirms archival.
  | 'SUMMARIZE_AND_DELETE' // GMI requests summarization then deletion.
  | 'SUMMARIZE_AND_ARCHIVE'// GMI requests summarization then archival.
  | 'RETAIN_FOR_DURATION'  // GMI requests retention for an additional, specified duration.
  | 'MARK_AS_CRITICAL'     // GMI marks the item as critical, implying high retention priority.
  | 'NO_ACTION_TAKEN'      // GMI reviewed but decided no specific action is needed from its side.
  | 'ACKNOWLEDGE_NOTIFICATION';// GMI acknowledges a non-negotiable notification.


/**
 * The GMI's response to a `MemoryLifecycleEvent`.
 *
 * @interface LifecycleActionResponse
 * @property {string} gmiId - The ID of the GMI responding.
 * @property {string} eventId - The ID of the `MemoryLifecycleEvent` this is a response to.
 * @property {LifecycleAction} actionTaken - The action the GMI has decided upon or agreed to.
 * @property {string} [rationale] - GMI's reasoning for its decision.
 * @property {string} [requestedRetentionDuration] - If `actionTaken` is `RETAIN_FOR_DURATION`, this specifies
 * the requested duration (e.g., "PT7D" for 7 days ISO 8601 duration, or simple "7d").
 * @property {Record<string, any>} [metadata] - Additional metadata or parameters related to the GMI's response.
 */
export interface LifecycleActionResponse {
  gmiId: string;
  eventId: string;
  actionTaken: LifecycleAction;
  rationale?: string;
  requestedRetentionDuration?: string; // e.g., "PT7D" (ISO 8601 duration)
  metadata?: Record<string, any>;
}

/**
 * A report on the GMI's health, including its sub-components.
 * @interface GMIHealthReport
 */
export interface GMIHealthReport {
  gmiId: string;
  personaId: string;
  timestamp: Date;
  overallStatus: 'HEALTHY' | 'DEGRADED' | 'UNHEALTHY' | 'ERROR';
  currentState: GMIPrimeState;
  memoryHealth?: {
    overallStatus: 'OPERATIONAL' | 'DEGRADED' | 'ERROR' | 'LIMITED';
    workingMemoryStats?: { itemCount: number; [key: string]: any };
    ragSystemStats?: { isHealthy: boolean; details?: any }; // From IRetrievalAugmentor.checkHealth()
    lifecycleManagerStats?: { isHealthy: boolean; details?: any }; // From IMemoryLifecycleManager.checkHealth()
    issues?: Array<{ severity: 'critical' | 'warning' | 'info'; description: string; component: string; details?: any }>;
  };
  dependenciesStatus?: Array<{
    componentName: string;
    status: 'HEALTHY' | 'UNHEALTHY' | 'DEGRADED' | 'UNKNOWN';
    details?: any;
  }>;
  recentErrors?: ReasoningTraceEntry[]; // Last few critical errors from reasoning trace
  uptimeSeconds?: number;
  activeTurnsProcessed?: number; // Since last reset/init
}


/**
 * @interface IGMI
 * @description Defines the contract for a Generalized Mind Instance (GMI).
 * The GMI is the core cognitive engine, responsible for processing interactions,
 * managing state, and generating responses based on its active Persona and various
 * contextual inputs.
 */
export interface IGMI {
  /**
   * A unique identifier for this GMI instance.
   * @readonly
   * @type {string}
   */
  readonly gmiId: string;

  /**
   * Timestamp of when this GMI instance was created.
   * @readonly
   * @type {Date}
   */
  readonly creationTimestamp: Date;

  /**
   * Initializes the GMI with a specific Persona and its base configuration.
   * This method must be called before the GMI can process any interactions.
   *
   * @async
   * @param {IPersonaDefinition} persona - The persona definition that dictates the GMI's behavior.
   * @param {GMIBaseConfig} config - The base configuration including necessary service dependencies.
   * @returns {Promise<void>} A promise that resolves upon successful initialization.
   * @throws {GMIError | Error} If initialization fails due to invalid persona, config, or dependency issues.
   */
  initialize(persona: IPersonaDefinition, config: GMIBaseConfig): Promise<void>;

  /**
   * Retrieves the currently active Persona definition for this GMI.
   *
   * @returns {IPersonaDefinition} The active persona.
   * @throws {GMIError} If the GMI is not initialized.
   */
  getPersona(): IPersonaDefinition;

  /**
   * Gets the unique ID of this GMI instance.
   * @returns {string} The GMI ID.
   */
  getGMIId(): string;

  /**
   * Gets the current primary operational state of the GMI.
   * @returns {GMIPrimeState} The current state.
   */
  getCurrentState(): GMIPrimeState;

  /**
   * Processes a single turn of interaction (e.g., user input, tool result)
   * and streams GMI output chunks. This is the primary method for interacting with the GMI.
   *
   * @async
   * @generator
   * @param {GMITurnInput} turnInput - The input for the current turn.
   * @yields {GMIOutputChunk} Chunks of the GMI's output, which can include text deltas,
   * tool call requests, reasoning state updates, or errors.
   * @throws {GMIError} If the GMI is not in a state to process turns or if a critical unrecoverable error occurs.
   */
  processTurnStream(turnInput: GMITurnInput): AsyncGenerator<GMIOutputChunk, void, undefined>;

  /**
   * Retrieves the GMI's reasoning trace, providing an audit trail of its internal operations.
   * Returns a read-only copy.
   *
   * @returns {Readonly<ReasoningTrace>} The reasoning trace.
   */
  getReasoningTrace(): Readonly<ReasoningTrace>;

  /**
   * (Internal Method, exposed for potential external triggering or advanced control)
   * Triggers the GMI's self-reflection cycle based on its active Persona's configuration.
   * During self-reflection, the GMI analyzes its recent performance, interactions, and state
   * to adapt its internal parameters (e.g., mood, understanding of user skill).
   * This method should ideally be called by the GMI itself periodically or based on triggers.
   *
   * @async
   * @returns {Promise<void>} A promise that resolves when the self-reflection cycle is complete.
   * @throws {GMIError} If an error occurs during the reflection process.
   */
  _triggerAndProcessSelfReflection(): Promise<void>;

  /**
   * Handles a memory lifecycle event, typically invoked by a `MemoryLifecycleManager`.
   * The GMI evaluates the event (e.g., a proposal to evict a memory item) and responds
   * with its decision or preference, potentially after internal reasoning or LLM consultation.
   *
   * @async
   * @param {MemoryLifecycleEvent} event - The memory lifecycle event details.
   * @returns {Promise<LifecycleActionResponse>} The GMI's response to the event, indicating the action it deems appropriate.
   * @throws {GMIError} If an error occurs while processing the event.
   */
  onMemoryLifecycleEvent(event: MemoryLifecycleEvent): Promise<LifecycleActionResponse>;

  /**
   * Analyzes the GMI's current memory state (working memory, RAG system connections, etc.)
   * and returns a health report subsection focused on memory.
   *
   * @async
   * @returns {Promise<GMIHealthReport['memoryHealth']>} A report on the GMI's memory health.
   * @throws {GMIError} If analysis fails.
   */
  analyzeAndReportMemoryHealth(): Promise<GMIHealthReport['memoryHealth']>;

  /**
   * Performs a comprehensive health check of the GMI, including its internal state,
   * memory systems, and critical dependencies (e.g., LLM providers).
   *
   * @async
   * @returns {Promise<GMIHealthReport>} A detailed health report for the GMI.
   */
  getOverallHealth(): Promise<GMIHealthReport>;

  /**
   * Gracefully shuts down the GMI instance, releasing any held resources and
   * ensuring a clean termination.
   *
   * @async
   * @returns {Promise<void>} A promise that resolves when shutdown is complete.
   */
  shutdown(): Promise<void>;
}