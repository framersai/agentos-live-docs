// backend/agentos/api/types/AgentOSInput.ts

import { VisionInputData, AudioInputData } from '../../cognitive_substrate/IGMI';

/**
 * @fileoverview Defines the unified input structure for the AgentOS API.
 * This interface encapsulates all possible data and options a user or
 * client might provide when interacting with an AgentOS instance.
 * @module backend/agentos/api/types/AgentOSInput
 */

/**
 * @typedef {Object} AgentOSInput
 * @property {string} userId - The ID of the authenticated user or a unique anonymous session ID.
 * This is crucial for session management, billing, and personalized experiences.
 * @property {string} sessionId - A unique identifier for the current client session.
 * This helps in maintaining conversational continuity and state in multi-device scenarios.
 * @property {string | null} textInput - The primary textual input from the user for this turn.
 * Can be `null` if the input is purely multimodal (e.g., only audio or vision).
 * @property {VisionInputData[]} [visionInputs] - Optional array of structured vision input data.
 * This can include image URLs, base64 encoded images, or references to visual observations.
 * @property {AudioInputData} [audioInput] - Optional structured audio input data.
 * This typically represents a transcription of speech, an audio file URL, or raw audio data.
 * @property {string} [selectedPersonaId] - The ID of the persona (agent) the user explicitly
 * wishes to interact with or switch to for this turn. If omitted, the system will
 * default to the last active persona for the session or a default system persona.
 * @property {Record<string, string>} [userApiKeys] - Optional user-provided API keys for
 * specific LLM providers (e.g., { "openai": "sk-...", "anthropic": "sk-..." }).
 * These keys allow users to utilize their own provider accounts, potentially unlocking
 * higher rate limits or different models based on their personal subscriptions.
 * @property {any} [userFeedback] - Optional explicit feedback from the user. This can be
 * structured data (e.g., `{ sentiment: 'positive', evaluation: 'good answer' }`)
 * or a simple string. This input is crucial for the GMI's adaptation and learning
 * mechanisms.
 * @property {string} [conversationId] - Optional ID of an ongoing conversation. If provided,
 * AgentOS will attempt to load and continue this specific conversation history.
 * If omitted, a new conversation context will be created or the existing session's
 * context will be used.
 * @property {ProcessingOptions} [options] - Optional processing options for the current turn.
 * These can influence how the GMI processes the input, e.g., enabling/disabling certain
 * features or overriding default behaviors.
 */
export interface AgentOSInput {
  userId: string;
  sessionId: string;
  textInput: string | null;
  visionInputs?: VisionInputData[];
  audioInput?: AudioInputData;
  selectedPersonaId?: string;
  userApiKeys?: Record<string, string>;
  userFeedback?: any; // Consider refining this type based on expected feedback structure
  conversationId?: string;
  options?: ProcessingOptions;
}

/**
 * @typedef {Object} ProcessingOptions
 * @property {boolean} [streamUICommands=true] - If true, UI commands generated by the GMI
 * (e.g., for dynamic blocks) will be streamed as part of the response.
 * @property {number} [maxToolCallIterations] - Overrides the default maximum number of
 * sequential tool calls an agent can make in a single turn. Useful for debugging
 * or controlling runaway agent behavior.
 * @property {string} [preferredModelId] - Suggests a specific LLM model ID to use for this
 * turn, overriding persona preferences. This can be useful for debugging or testing
 * specific model behaviors.
 * @property {string} [preferredProviderId] - Suggests a specific LLM provider ID to use.
 * @property {number} [temperature] - Overrides the default temperature setting for the LLM
 * call in this turn. Controls randomness/creativity.
 * @property {number} [topP] - Overrides the default top_p setting for the LLM call.
 * @property {number} [maxTokens] - Overrides the default maximum number of tokens for the
 * LLM's response in this turn.
 * @property {boolean} [disableAdaptation] - If true, the GMI will not apply any adaptive
 * learning or mood changes based on user feedback for this specific turn.
 * @property {boolean} [debugMode] - If true, more verbose logging and reasoning traces
 * will be included in the GMI output.
 */
export interface ProcessingOptions {
  streamUICommands?: boolean;
  maxToolCallIterations?: number;
  preferredModelId?: string;
  preferredProviderId?: string;
  temperature?: number;
  topP?: number;
  maxTokens?: number;
  disableAdaptation?: boolean;
  debugMode?: boolean;
}
