# ğŸ’¾ AgentOS RAG System

[![Version](https://img.shields.io/badge/version-1.0-blue.svg)](#) [![Status](https://img.shields.io/badge/status-Production%20Ready-green.svg)](#)

> **Intelligent memory and knowledge retrieval system that provides GMIs with sophisticated long-term memory capabilities**

---

## ğŸš€ Quick Navigation

| Component | Description | Jump To |
|-----------|-------------|---------|
| ğŸŒŸ **[Overview](#-overview)** | System introduction and key features | [â†“](#-overview) |
| ğŸ—ï¸ **[Core Components](#ï¸-core-components)** | Architecture and key classes | [â†“](#ï¸-core-components) |
| ğŸ“‚ **[Memory Categories](#-memory-categories)** | Information organization system | [â†“](#-memory-categories) |
| ğŸ”„ **[Information Flow](#-information-flow)** | Data processing pipelines | [â†“](#-information-flow) |
| ğŸ’½ **[Vector Stores](#-vector-store-implementations)** | Storage backend options | [â†“](#-vector-store-implementations) |
| â™»ï¸ **[Memory Lifecycle](#ï¸-memory-lifecycle-management)** | Automated memory management | [â†“](#ï¸-memory-lifecycle-management) |

**ğŸ”— Related Documentation:**
- [ğŸ“– Main README](../README.md) - AgentOS overview and getting started
- [ğŸ¯ Prompting System](PROMPTS.md) - Advanced prompt engineering and personas
- [ğŸ”§ LLM Providers](../backend/agentos/core/llm/providers/README.md) - Multi-provider LLM integration
- [ğŸ§  Technical Deep Dive](ARCHITECTURE.md) - Complete system architecture
- [ğŸš€ Getting Started](GETTING_STARTED.md) - Step-by-step setup guide

---

## ğŸ“‹ Table of Contents

- [ğŸŒŸ Overview](#-overview)
- [ğŸ—ï¸ Core Components](#ï¸-core-components)
- [ğŸ“‚ Memory Categories](#-memory-categories)
- [ğŸ”„ Information Flow](#-information-flow)
- [ğŸ’½ Vector Store Implementations](#-vector-store-implementations)
- [â™»ï¸ Memory Lifecycle Management](#ï¸-memory-lifecycle-management)
- [âš™ï¸ Configuration](#ï¸-configuration)
- [ğŸ“š API Reference](#-api-reference)
- [ğŸš€ Getting Started](#-getting-started)
- [âœ¨ Best Practices](#-best-practices)

---

## ğŸŒŸ Overview

The AgentOS RAG system transcends simple vector lookups to provide sophisticated, AI-powered memory management. It enables GMIs to maintain rich, contextual memory that evolves and adapts over time.

### **ğŸ¯ Key Features**

```mermaid
graph LR
    A[ğŸ“‚ Categorized Memory] --> B[ğŸ§  Intelligent Processing]
    B --> C[â™»ï¸ Lifecycle Management] 
    C --> D[ğŸ¤– GMI Integration]
    D --> E[âš¡ Real-time Retrieval]
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5  
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#fce4ec
```

| Feature | Description | Benefit |
|---------|-------------|---------|
| ğŸ“‚ **Categorized Memory** | Organized information storage by type and purpose | Efficient retrieval and management |
| ğŸ§  **Intelligent Ingestion** | Smart preprocessing and deduplication | High-quality knowledge base |
| â™»ï¸ **Lifecycle Management** | Automated memory policies with GMI negotiation | Optimal storage utilization |
| ğŸ¤– **GMI Integration** | Seamless AI decision-making integration | Natural memory usage |
| âš¡ **Real-time Context** | Fast retrieval for AI responses | Enhanced user experiences |

### **ğŸ—ï¸ System Architecture**

```mermaid
graph TB
    subgraph "ğŸ§  AI Layer"
        GMI[GMI Instance]
        Reasoning[Reasoning Engine]
    end
    
    subgraph "ğŸ”„ RAG Core"
        RA[Retrieval Augmentor]
        EM[Embedding Manager]
        VSM[Vector Store Manager]
    end
    
    subgraph "ğŸ’¾ Storage Layer"
        Pinecone[Pinecone]
        Weaviate[Weaviate]  
        Local[Local Storage]
    end
    
    subgraph "â™»ï¸ Management Layer"
        LM[Lifecycle Manager]
        Policy[Memory Policies]
        Negotiator[GMI Negotiator]
    end
    
    GMI --> RA
    Reasoning --> RA
    RA --> EM
    RA --> VSM
    EM --> VSM
    VSM --> Pinecone
    VSM --> Weaviate
    VSM --> Local
    
    RA --> LM
    LM --> Policy
    LM --> Negotiator
    Negotiator --> GMI
    
    style GMI fill:#e1f5fe
    style RA fill:#f3e5f5
    style LM fill:#e8f5e8
```

---

## ğŸ—ï¸ Core Components

### **ğŸ¯ RetrievalAugmentor**

The central orchestrator for all RAG operations - the brain of the memory system.

```typescript
interface IRetrievalAugmentor {
  retrieveContext(request: RetrievalRequest): Promise<ProcessedRetrievedContext>;
  ingestInformation(request: IngestionRequest): Promise<IngestionResult>;
  deleteInformation(request: DeletionRequest): Promise<DeletionResult>;
}
```

**ğŸ”‘ Key Responsibilities:**
- ğŸ” Handle retrieval queries from GMIs
- ğŸ“¥ Process and store new information intelligently
- ğŸ”— Coordinate with memory lifecycle manager
- ğŸ”„ Apply update strategies for similar content

### **ğŸ§  EmbeddingManager** 

Manages text-to-vector conversion using various embedding models.

```typescript
interface IEmbeddingManager {
  generateEmbeddings(text: string, options?: EmbeddingOptions): Promise<number[]>;
  generateBatchEmbeddings(texts: string[], options?: EmbeddingOptions): Promise<number[][]>;
}
```

**âœ¨ Features:**
- ğŸ¯ Support for multiple embedding models
- âš¡ Caching for improved performance  
- ğŸ“¦ Batch processing capabilities
- ğŸ’° Cost tracking and optimization

### **ğŸ’½ VectorStoreManager**

Abstracts interaction with different vector database providers.

```typescript
interface IVectorStoreManager {
  getProvider(providerId: string): IVectorStore;
  upsertDocument(collectionId: string, document: VectorDocument): Promise<void>;
  queryDocuments(collectionId: string, query: VectorQuery): Promise<VectorDocument[]>;
}
```

**ğŸ¯ Supported Providers:**
- â˜ï¸ **Pinecone** - Cloud-hosted, high-performance
- ğŸ  **Weaviate** - Self-hosted, feature-rich
- ğŸ’¾ **In-memory** - Development and testing
- ğŸ“ **Local file** - Embedded databases

---

## ğŸ“‚ Memory Categories

The RAG system organizes information into logical categories for optimal management and retrieval:

```mermaid
mindmap
  root((ğŸ“‚ Memory Categories))
    ğŸ¤– Personal LLM Experience
      Learning patterns
      Interaction insights
      Subject expertise
      GMI negotiation
    ğŸ‘¤ User Explicit Memory  
      Personal preferences
      User-provided data
      Privacy controls
      Direct input
    ğŸŒ Shared Knowledge Base
      General knowledge
      Documentation
      Reference materials
      Multi-user access
```

### **ğŸ¤– Personal LLM Experience** (`personal_llm_experience`)

**Purpose:** GMI's learned knowledge and behavioral patterns
```typescript
{
  category: MemoryCategory.PERSONAL_LLM_EXPERIENCE,
  content: "User prefers concise Python explanations with working examples",
  metadata: {
    confidence: 0.95,
    learningSource: "interaction_pattern",
    reinforcements: 12
  }
}
```

**Characteristics:**
- ğŸ§  GMI's learned knowledge and patterns
- ğŸ“Š Interaction summaries and insights  
- ğŸ¤ Subject to GMI negotiation for lifecycle events
- ğŸ”„ Continuously updated through interactions

### **ğŸ‘¤ User Explicit Memory** (`user_explicit_memory`)

**Purpose:** User-provided information and preferences
```typescript
{
  category: MemoryCategory.USER_EXPLICIT_MEMORY,
  content: "Project uses FastAPI with PostgreSQL, deployed on AWS ECS",
  metadata: {
    source: "user_direct_input",
    importance: "high",
    projectContext: "web_api_development"
  }
}
```

**Characteristics:**
- ğŸ“ User-provided information and preferences
- ğŸ”’ Personal data and context with privacy controls
- ğŸ‘¤ Subject to user privacy controls
- ğŸ¯ High retention priority

### **ğŸŒ Shared Knowledge Base** (`shared_knowledge_base`)

**Purpose:** General knowledge accessible to multiple users
```typescript
{
  category: MemoryCategory.SHARED_KNOWLEDGE_BASE,
  content: "FastAPI best practices for async database operations",
  metadata: {
    source: "documentation_crawl",
    lastUpdated: "2024-01-15",
    reliability: "high"
  }
}
```

**Characteristics:**
- ğŸ“š General knowledge accessible to multiple users
- ğŸ“– Documentation and reference materials
- â° Longer retention policies
- ğŸ”„ Periodic updates from authoritative sources

```typescript
enum MemoryCategory {
  PERSONAL_LLM_EXPERIENCE = 'personal_llm_experience',
  USER_EXPLICIT_MEMORY = 'user_explicit_memory', 
  SHARED_KNOWLEDGE_BASE = 'shared_knowledge_base'
}
```

---

## ğŸ”„ Information Flow

### **ğŸ“¥ Retrieval Process**

```mermaid
graph TD
    A[ğŸ§  GMI Query] --> B[ğŸ¯ Query Optimization]
    B --> C[ğŸ” Embedding Generation]
    C --> D[ğŸ’½ Vector Store Query]
    D --> E[ğŸ“Š Result Ranking]
    E --> F[ğŸ”§ Context Formatting]
    F --> G[ğŸ“¤ Return to GMI]
    
    H[âš™ï¸ Query Enhancement] --> B
    I[ğŸ“ˆ Relevance Scoring] --> E
    J[ğŸ’° Token Budgeting] --> F
    
    style A fill:#e3f2fd
    style G fill:#e8f5e8
```

**Process Steps:**
1. **ğŸ¯ Query Analysis** - Parse and optimize the search query
2. **ğŸ” Embedding Generation** - Convert query to vector representation
3. **ğŸ’½ Vector Search** - Query across configured vector stores
4. **ğŸ“Š Result Processing** - Rank and filter results by relevance
5. **ğŸ”§ Context Formatting** - Format for GMI consumption within token limits

### **ğŸ“¤ Ingestion Process**

```mermaid
graph TD
    A[ğŸ“„ Information Input] --> B[ğŸ” Preprocessing]
    B --> C[ğŸ”„ Similarity Check]
    C --> D[ğŸ“‹ Update Strategy]
    D --> E[ğŸ§  Embedding Generation]
    E --> F[ğŸ’¾ Vector Storage]
    
    G[â™»ï¸ Lifecycle Check] --> B
    H[ğŸ¤– GMI Negotiation] --> D
    I[ğŸš« Deduplication] --> E
    
    style A fill:#e3f2fd
    style F fill:#e8f5e8
```

**Process Steps:**
1. **ğŸ” Preprocessing** - Clean and structure the input information
2. **ğŸ”„ Similarity Check** - Identify similar existing content
3. **ğŸ“‹ Strategy Selection** - Choose appropriate update strategy
4. **ğŸ§  Embedding Generation** - Create vector representations
5. **ğŸ’¾ Storage** - Persist in configured vector store

### **ğŸ”„ Update Strategies**

The system supports several strategies for handling similar content:

| Strategy | When to Use | GMI Involvement | Description |
|----------|-------------|-----------------|-------------|
| ğŸ”„ **Overwrite** | Content is clearly outdated | âŒ No | Replace existing content completely |
| ğŸš« **Deduplicate** | Highly similar content exists | âŒ No | Skip storage to avoid redundancy |
| ğŸ¤ **Merge** | Complementary information | âœ… Yes | GMI assists in combining content |
| ğŸ“š **Version** | Historical tracking needed | âŒ No | Create versioned entries |

---

## ğŸ’½ Vector Store Implementations

### **â˜ï¸ Pinecone Integration**

```typescript
class PineconeVectorStore implements IVectorStore {
  constructor(private config: PineconeConfig) {}
  
  async upsert(documents: VectorDocument[]): Promise<UpsertResult> {
    // Pinecone-specific implementation with batching
    const batches = this.createBatches(documents, 100);
    const results = await Promise.all(
      batches.map(batch => this.pineconeIndex.upsert({ vectors: batch }))
    );
    return this.aggregateResults(results);
  }
  
  async query(queryVector: number[], options: QueryOptions): Promise<QueryResult> {
    const response = await this.pineconeIndex.query({
      vector: queryVector,
      topK: options.maxResults,
      filter: options.metadataFilter,
      includeMetadata: true
    });
    return this.formatResults(response);
  }
}
```

**âœ¨ Features:**
- âš¡ High-performance cloud hosting
- ğŸ“ˆ Automatic scaling
- ğŸ” Advanced filtering capabilities
- ğŸ’° Usage-based pricing

### **ğŸ  Weaviate Integration**

```typescript
class WeaviateVectorStore implements IVectorStore {
  constructor(private config: WeaviateConfig) {}
  
  async upsert(documents: VectorDocument[]): Promise<UpsertResult> {
    const batch = this.weaviate.batch.objectsBatcher();
    documents.forEach(doc => {
      batch.withObject({
        class: this.config.className,
        properties: doc.metadata,
        vector: doc.embedding
      });
    });
    return await batch.do();
  }
  
  async query(queryVector: number[], options: QueryOptions): Promise<QueryResult> {
    const result = await this.weaviate.graphql
      .get()
      .withClassName(this.config.className)
      .withNearVector({ vector: queryVector })
      .withLimit(options.maxResults)
      .withFields('_additional { certainty distance }')
      .do();
    return this.formatResults(result);
  }
}
```

**âœ¨ Features:**
- ğŸ  Self-hosted control
- ğŸ” Rich query capabilities
- ğŸ“Š Built-in analytics
- ğŸ›¡ï¸ Data sovereignty

### **ğŸ’¾ Local Development Options**

For development and testing environments:

```typescript
// âš¡ Fast, ephemeral storage
class InMemoryVectorStore implements IVectorStore {
  private documents: Map<string, VectorDocument> = new Map();
  
  async query(queryVector: number[], options: QueryOptions): Promise<QueryResult> {
    const results = Array.from(this.documents.values())
      .map(doc => ({
        document: doc,
        similarity: this.cosineSimilarity(queryVector, doc.embedding)
      }))
      .sort((a, b) => b.similarity - a.similarity)
      .slice(0, options.maxResults);
    
    return { documents: results.map(r => r.document) };
  }
}

// ğŸ’¾ Persistent file-based storage  
class LocalFileVectorStore implements IVectorStore {
  constructor(private dataPath: string) {}
  
  async upsert(documents: VectorDocument[]): Promise<UpsertResult> {
    const existingData = await this.loadFromFile();
    documents.forEach(doc => existingData.set(doc.id, doc));
    await this.saveToFile(existingData);
    return { upsertedCount: documents.length };
  }
}
```

---

## â™»ï¸ Memory Lifecycle Management

### **ğŸ¯ MemoryLifecycleManager**

Automates memory management based on policies and user tiers.

```typescript
interface IMemoryLifecycleManager {
  enforceStoragePolicy(event: LifecycleEvent): Promise<PolicyResult>;
  scheduleCleanupTasks(): void;
  negotiateWithGMI(gmi: IGMI, event: MemoryLifecycleEvent): Promise<NegotiationResult>;
}
```

### **ğŸ“‹ Policy Types**

```mermaid
graph LR
    A[ğŸ“… Retention Policies] --> B[Time-based expiration]
    C[ğŸ’¾ Quota Policies] --> D[Storage limits by tier]
    E[ğŸ—‘ï¸ Eviction Strategies] --> F[LRU, importance, custom]
    
    style A fill:#e3f2fd
    style C fill:#f3e5f5
    style E fill:#e8f5e8
```

| Policy Type | Description | Configuration |
|-------------|-------------|---------------|
| **ğŸ“… Retention** | Time-based document expiration | `retentionDays: 90` |
| **ğŸ’¾ Quota** | Storage limits based on user tiers | `maxDocuments: 10000` |
| **ğŸ—‘ï¸ Eviction** | Smart removal strategies | `strategy: "importance_based"` |

### **ğŸ¤– GMI Negotiation Process**

When personal memories are affected, the system engages in intelligent negotiation:

```mermaid
sequenceDiagram
    participant LM as â™»ï¸ Lifecycle Manager
    participant GMI as ğŸ§  GMI Instance
    participant Storage as ğŸ’¾ Vector Store
    
    LM->>GMI: ğŸ“¤ Lifecycle Event Notification
    GMI->>GMI: ğŸ¤” Analyze Memory Importance
    GMI->>LM: ğŸ’¡ Propose Alternative Action
    LM->>LM: âš–ï¸ Evaluate Proposal
    LM->>Storage: ğŸ”„ Execute Agreed Action
    Storage->>LM: âœ… Confirmation
    LM->>GMI: ğŸ“‹ Action Complete
```

**Negotiation Example:**
```typescript
interface MemoryLifecycleEvent {
  type: 'eviction' | 'archival' | 'expiration';
  documentId: string;
  reason: string;
  proposedAction: LifecycleAction;
  negotiable: boolean;
}

// GMI can propose alternatives like:
const gmiProposal = {
  action: 'summarize_and_compress',
  reasoning: 'This contains important user context patterns',
  alternativeRetention: '30_days_compressed'
};
```

---

## âš™ï¸ Configuration

### **ğŸ—ï¸ Vector Store Configuration**

```typescript
interface RagSystemConfig {
  providers: VectorStoreProviderConfig[];
  collections: RagCollectionConfig[];
  defaultEmbeddingModel: string;
  lifecyclePolicies: LifecyclePolicyConfig[];
}
```

### **ğŸ“‚ Collection Configuration**

```typescript
interface RagCollectionConfig {
  id: string;
  name: string;
  category: MemoryCategory;
  vectorStoreProviderId: string;
  embeddingDimensions: number;
  defaultRetentionDays?: number;
  maxDocuments?: number;
  evictionStrategy: EvictionStrategy;
}
```

### **ğŸ’¡ Example Configuration**

```json
{
  "providers": [
    {
      "id": "pinecone-main",
      "type": "pinecone",
      "config": {
        "apiKey": "${PINECONE_API_KEY}",
        "environment": "us-west1-gcp",
        "indexName": "agentos-memory"
      }
    },
    {
      "id": "weaviate-local", 
      "type": "weaviate",
      "config": {
        "url": "http://localhost:8080",
        "className": "AgentMemory"
      }
    }
  ],
  "collections": [
    {
      "id": "user-memory",
      "name": "User Explicit Memory",
      "category": "user_explicit_memory",
      "vectorStoreProviderId": "pinecone-main",
      "embeddingDimensions": 1536,
      "defaultRetentionDays": 365,
      "maxDocuments": 10000,
      "evictionStrategy": "importance_based"
    },
    {
      "id": "gmi-experience",
      "name": "GMI Learning Experience", 
      "category": "personal_llm_experience",
      "vectorStoreProviderId": "pinecone-main",
      "embeddingDimensions": 1536,
      "defaultRetentionDays": 180,
      "maxDocuments": 5000,
      "evictionStrategy": "lru_with_gmi_negotiation"
    }
  ],
  "lifecyclePolicies": [
    {
      "category": "shared_knowledge_base",
      "retentionDays": 730,
      "maxSizeGB": 10,
      "compressionEnabled": true
    }
  ]
}
```

---

## ğŸ“š API Reference

### **ğŸ” RetrievalRequest**

```typescript
interface RetrievalRequest {
  query: string;                           // Search query text
  targetCategories: MemoryCategory[];      // Which memory categories to search
  userId: string;                          // User identifier
  gmiId?: string;                         // Optional GMI identifier
  maxResults?: number;                    // Maximum results to return (default: 5)
  similarityThreshold?: number;           // Minimum similarity score (0-1)
  filters?: QueryFilter[];                // Additional metadata filters
  contextWindow?: number;                 // Token budget for context
}
```

### **ğŸ“¥ IngestionRequest**

```typescript
interface IngestionRequest {
  textContent: string;                    // Content to store
  category: MemoryCategory;              // Memory category
  userId: string;                        // User identifier  
  gmiId?: string;                       // Optional GMI identifier
  documentId?: string;                  // Optional document ID for updates
  updateStrategy: UpdateStrategy;       // How to handle similar content
  metadata?: Record<string, any>;       // Additional metadata
  importance?: number;                  // Importance score (0-1)
  source?: string;                      // Content source identifier
}
```

### **ğŸ“¤ ProcessedRetrievedContext**

```typescript
interface ProcessedRetrievedContext {
  augmentedPromptText: string;          // Formatted context for LLM
  sourceDocuments: RetrievedDocument[]; // Source documents with metadata
  totalTokensUsed: number;             // Token count for budgeting
  queryEmbeddingCost: number;          // Embedding generation cost
  retrievalLatencyMs: number;          // Query latency metrics
  relevanceScores: number[];           // Similarity scores for each result
  categoriesSearched: MemoryCategory[]; // Which categories were queried
}
```

---

## ğŸš€ Getting Started

### **ğŸ“¦ Basic Setup**

```bash
# ğŸ“¥ Install dependencies
npm install @agentos/rag
```

### **âš™ï¸ Configure Vector Store**

```typescript
// ğŸ“Œ Pinecone Configuration
const pineconeConfig = {
  provider: 'pinecone',
  apiKey: process.env.PINECONE_API_KEY,
  environment: 'us-west1-gcp',
  indexName: 'agentos-memory'
};

// ğŸ  Weaviate Configuration  
const weaviateConfig = {
  provider: 'weaviate',
  url: 'http://localhost:8080',
  className: 'AgentMemory'
};
```

### **ğŸš€ Initialize RAG System**

```typescript
import { 
  RetrievalAugmentor, 
  VectorStoreManager, 
  EmbeddingManager, 
  MemoryLifecycleManager 
} from '@agentos/rag';

const ragSystem = new RetrievalAugmentor({
  vectorStoreManager: new VectorStoreManager({
    providers: [pineconeConfig, weaviateConfig],
    defaultProvider: 'pinecone'
  }),
  embeddingManager: new EmbeddingManager({
    model: 'text-embedding-ada-002',
    batchSize: 100,
    cachingEnabled: true
  }),
  memoryLifecycleManager: new MemoryLifecycleManager({
    policies: lifecyclePolicies,
    gmiNegotiationEnabled: true
  })
});
```

### **ğŸ’¡ Usage Examples**

#### **ğŸ“¥ Storing Information**

```typescript
// ğŸ’¾ Store user preference
await ragSystem.ingestInformation({
  textContent: "User prefers concise explanations in Python with working examples",
  category: MemoryCategory.USER_EXPLICIT_MEMORY,
  userId: 'user123',
  updateStrategy: 'merge_if_similar_propose_gmi',
  importance: 0.8,
  metadata: {
    domain: 'programming_preferences',
    language: 'python'
  }
});

// ğŸ§  Store GMI learning
await ragSystem.ingestInformation({
  textContent: "Successfully debugging FastAPI async issues using print statements was effective for this user",
  category: MemoryCategory.PERSONAL_LLM_EXPERIENCE, 
  userId: 'user123',
  gmiId: 'gmi-coding-assistant',
  updateStrategy: 'merge_with_existing',
  importance: 0.6,
  metadata: {
    interaction_type: 'debugging_session',
    success_rate: 0.9
  }
});
```

#### **ğŸ” Retrieving Context**

```typescript
// ğŸ¯ Retrieve relevant context for coding question
const context = await ragSystem.retrieveContext({
  query: "How should I explain this Python async/await concept?",
  targetCategories: [
    MemoryCategory.USER_EXPLICIT_MEMORY,
    MemoryCategory.PERSONAL_LLM_EXPERIENCE
  ],
  userId: 'user123',
  maxResults: 5,
  similarityThreshold: 0.7,
  contextWindow: 1000 // Token budget
});

console.log('Retrieved context:', context.augmentedPromptText);
console.log('Source documents:', context.sourceDocuments.length);
console.log('Tokens used:', context.totalTokensUsed);
```

#### **ğŸ” Advanced Querying with Filters**

```typescript
// ğŸ¯ Search with metadata filters
const filteredContext = await ragSystem.retrieveContext({
  query: "debugging techniques for web APIs",
  targetCategories: [MemoryCategory.PERSONAL_LLM_EXPERIENCE],
  userId: 'user123',
  maxResults: 3,
  filters: [
    { field: 'domain', operator: 'equals', value: 'web_development' },
    { field: 'success_rate', operator: 'greater_than', value: 0.8 }
  ]
});
```

---

## âœ¨ Best Practices

### **ğŸ“Š Content Organization**

| âœ… Do | âŒ Don't | ğŸ’¡ Why |
|-------|----------|---------|
| Use appropriate memory categories | Mix different content types | Better retrieval accuracy |
| Include rich metadata | Store bare minimum data | Enhanced filtering capabilities |
| Structure content for chunking | Store very long, unstructured text | Optimal embedding quality |
| Set importance scores | Treat all content equally | Better lifecycle management |

### **âš¡ Performance Optimization**

```markdown
## ğŸš€ Optimization Checklist

### ğŸ“¦ Batching
- âœ… Generate embeddings in batches of 100
- âœ… Batch vector store operations
- âœ… Use async processing for large datasets

### ğŸ’¾ Caching  
- âœ… Cache frequently accessed embeddings
- âœ… Implement query result caching
- âœ… Use CDN for static knowledge base content

### ğŸ¯ Query Optimization
- âœ… Set appropriate similarity thresholds
- âœ… Use metadata filters to narrow searches
- âœ… Implement query rewriting for better results

### ğŸ“Š Monitoring
- âœ… Track query latency and accuracy
- âœ… Monitor storage costs and usage
- âœ… Analyze retrieval patterns for optimization
```

### **â™»ï¸ Memory Management**

```typescript
// âœ… Good: Specific retention policies
const retentionPolicy = {
  category: MemoryCategory.USER_EXPLICIT_MEMORY,
  retentionDays: 365,
  compressionAfterDays: 90,
  gmiNegotiationEnabled: true
};

// âŒ Bad: Generic "keep everything forever"
const badPolicy = {
  retentionDays: -1, // Never delete
  compressionEnabled: false
};
```

### **ğŸ”’ Security Considerations**

```markdown
## ğŸ›¡ï¸ Security Best Practices

### ğŸ” Data Isolation
- Ensure proper user data separation
- Implement access controls for sensitive information
- Use encrypted connections to vector stores

### ğŸ‘¤ Privacy Protection
- Allow users to delete their memory data
- Implement data anonymization for shared knowledge
- Regular auditing of stored content

### ğŸ¢ Compliance
- Follow GDPR/CCPA requirements for data retention
- Implement data portability features
- Maintain audit logs for data operations
```

---

## ğŸ¤ Contributing

### **ğŸ› ï¸ Development Setup**

```bash
# ğŸ“¥ Clone and setup
git clone https://github.com/agentos/agentos.git
cd agentos
npm install

# ğŸ§ª Run RAG-specific tests
npm run test:rag
npm run test:integration:rag

# ğŸš€ Start development environment with local vector store
npm run dev:rag-local
```

### **ğŸ¯ Contribution Areas**

| Area | Skills | Impact | Difficulty |
|------|--------|---------|------------|
| ğŸ’½ **Vector Store Integrations** | Database APIs, TypeScript | ğŸ”¥ High | ğŸŸ¡ Medium |
| ğŸ§  **Embedding Models** | ML, Python/TypeScript | ğŸ”¥ High | ğŸ”´ Hard |
| â™»ï¸ **Lifecycle Policies** | Algorithms, Policy Design | ğŸŸ¡ Medium | ğŸŸ¡ Medium |
| ğŸ§ª **Testing & Benchmarks** | Testing, Performance | ğŸŸ¡ Medium | ğŸŸ¢ Easy |
| ğŸ“š **Documentation** | Technical Writing | ğŸŸ¡ Medium | ğŸŸ¢ Easy |

### **ğŸ”§ Adding New Vector Store**

```typescript
// 1. Implement the IVectorStore interface
class MyVectorStore implements IVectorStore {
  async upsert(documents: VectorDocument[]): Promise<UpsertResult> {
    // Your implementation
  }
  
  async query(query: VectorQuery): Promise<QueryResult> {
    // Your implementation  
  }
  
  async delete(documentIds: string[]): Promise<DeletionResult> {
    // Your implementation
  }
}

// 2. Register with VectorStoreManager
const storeManager = new VectorStoreManager();
storeManager.registerProvider('my-store', MyVectorStore);

// 3. Add configuration schema
interface MyVectorStoreConfig {
  apiKey: string;
  endpoint: string;
  // Other config options
}
```

---

## ğŸ“„ License & Links

### **ğŸ“œ License**
This project is licensed under the MIT License - see the [LICENSE](../LICENSE) file for details.

### **ğŸ”— Related Documentation**
- **[ğŸ“– Main README](../README.md)** - AgentOS overview and getting started
- **[ğŸ¯ Advanced Prompting System](PROMPTS.md)** - Prompt engineering and persona creation
- **[ğŸ”§ LLM Provider System](../backend/agentos/core/llm/providers/README.md)** - Multi-provider LLM integration
- **[ğŸ§  Technical Deep Dive](ARCHITECTURE.md)** - Complete technical architecture
- **[ğŸš€ Getting Started Guide](GETTING_STARTED.md)** - Step-by-step setup tutorial

### **ğŸŒ Community & Support**
- **[ğŸ™ GitHub Repository](https://github.com/agentos/agentos)**
- **[ğŸ“š Documentation Site](https://docs.agentos.ai)**
- **[ğŸ’¬ Discord Community](https://discord.gg/agentos)**
- **[ğŸ› Issue Tracker](https://github.com/agentos/agentos/issues)**
- **[ğŸ’¡ Feature Requests](https://github.com/agentos/agentos/discussions)**

---

<div align="center">

**ğŸ’¾ Intelligent Memory for Intelligent Agents**

*Empowering AI with sophisticated, adaptive memory capabilities*

[â­ Star on GitHub](https://github.com/agentos/agentos) â€¢ [ğŸ“§ Newsletter](https://agentos.ai/newsletter) â€¢ [ğŸ¤ Contribute](../CONTRIBUTING.md)

</div>