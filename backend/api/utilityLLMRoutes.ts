/**
 * @file backend/api/utilityLLMRoutes.ts
 * @module backend/api/utilityLLMRoutes
 * @version 1.1.0
 *
 * @description
 * This module defines Express routes for various utility functions powered by Large Language Models (LLMs).
 * These utilities can include direct prompting, text summarization, translation, SEO keyword generation,
 * content classification, sentiment analysis, and more. The routes leverage a dedicated `IUtilityLLMService`
 * for the core LLM interactions and are protected by authentication to manage access and potential costs.
 *
 * The routes are designed to be stateless and provide general-purpose AI utilities that can be
 * consumed by various parts of the application or even other microservices.
 *
 * Key Dependencies:
 * - `express`: For router creation and request/response handling.
 * - `../services/user_auth/IAuthService`: For authentication middleware.
 * - `../middleware/authenticateTokenMiddleware`: Provides `authenticateToken` and `AuthenticatedRequest`.
 * - `../utils/errors`: For standardized error handling (`GMIError`, `GMIErrorCode`, `ErrorFactory`).
 */

import { Router, Request, Response, NextFunction } from 'express';
import { IAuthService } from '../services/user_auth/IAuthService'; // Actual IAuthService
import { AuthenticatedRequest, authenticateToken } from '../middleware/authenticateTokenMiddleware';
import { GMIError, GMIErrorCode, ErrorFactory, createGMIErrorFromError } from '../utils/errors';

// --- Request and Response DTOs for Utility LLM Functions ---

/**
 * @interface DirectPromptRequestDto
 * @description DTO for raw/direct prompting to an LLM.
 * @property {string} prompt - The prompt string to send to the LLM.
 * @property {string} [context] - Optional: Additional context to provide alongside the prompt.
 * @property {string} [modelId] - Optional: Specific model ID to use for this request, overriding service default.
 * @property {Record<string, any>} [completionOptions] - Optional: Provider-specific completion options (e.g., temperature, maxTokens).
 */
interface DirectPromptRequestDto {
  prompt: string;
  context?: string;
  modelId?: string;
  completionOptions?: Record<string, any>;
}

/**
 * @interface DirectPromptResponseDto
 * @description DTO for the response from a direct LLM prompt.
 * @property {string} responseText - The text generated by the LLM.
 * @property {string} modelUsed - The model ID that was used for generation.
 * @property {any} [usage] - Optional: Token usage and cost information.
 */
interface DirectPromptResponseDto {
  responseText: string;
  modelUsed: string;
  usage?: any; // Define a more specific ModelUsage type if available globally
}

/**
 * @interface SummarizationRequestDto
 * @description DTO for text summarization requests.
 * @property {string} textToSummarize - The text content to be summarized.
 * @property {'short' | 'medium' | 'long' | number} [desiredLength='medium'] - Desired length of the summary (e.g., number of sentences or abstract keywords).
 * @property {'general' | 'bullet_points' | 'paragraph' | 'key_sentences'} [format='paragraph'] - Desired format of the summary.
 * @property {string} [context] - Optional: Context about the text to improve summary quality.
 * @property {string} [modelId] - Optional: Specific model ID for summarization.
 */
interface SummarizationRequestDto {
  textToSummarize: string;
  desiredLength?: 'short' | 'medium' | 'long' | number;
  format?: 'general' | 'bullet_points' | 'paragraph' | 'key_sentences';
  context?: string;
  modelId?: string;
}

/**
 * @interface SummarizationResponseDto
 * @description DTO for text summarization responses.
 * @property {string} summary - The generated summary text.
 * @property {string} modelUsed - The model ID used for summarization.
 */
interface SummarizationResponseDto {
  summary: string;
  modelUsed: string;
}

/**
 * @interface TranslationRequestDto
 * @description DTO for text translation requests.
 * @property {string} textToTranslate - The text content to be translated.
 * @property {string} targetLanguage - The target language code (e.g., "es", "fr", "de").
 * @property {string} [sourceLanguage] - Optional: Source language code. If omitted, the LLM may attempt auto-detection.
 * @property {string} [modelId] - Optional: Specific model ID for translation.
 */
interface TranslationRequestDto {
  textToTranslate: string;
  targetLanguage: string; // BCP 47 language code
  sourceLanguage?: string; // BCP 47 language code
  modelId?: string;
}

/**
 * @interface TranslationResponseDto
 * @description DTO for text translation responses.
 * @property {string} translatedText - The translated text.
 * @property {string} detectedSourceLanguage - The source language detected by the model (if sourceLanguage was not provided).
 * @property {string} modelUsed - The model ID used for translation.
 */
interface TranslationResponseDto {
  translatedText: string;
  detectedSourceLanguage?: string;
  modelUsed: string;
}

/**
 * @interface SeoKeywordRequestDto
 * @description DTO for SEO keyword generation requests.
 * @property {string} content - The text content (e.g., article, product description) to analyze for keywords.
 * @property {number} [maxKeywords=10] - The maximum number of keywords to generate.
 * @property {string} [language] - Optional: Language of the content for more accurate keyword extraction.
 * @property {string} [modelId] - Optional: Specific model ID for keyword generation.
 */
interface SeoKeywordRequestDto {
  content: string;
  maxKeywords?: number;
  language?: string;
  modelId?: string;
}

/**
 * @interface SeoKeywordResponseDto
 * @description DTO for SEO keyword generation responses.
 * @property {string[]} keywords - An array of suggested SEO keywords.
 * @property {string} modelUsed - The model ID used for generation.
 */
interface SeoKeywordResponseDto {
  keywords: string[];
  modelUsed: string;
}

/**
 * @interface ContentClassificationRequestDto
 * @description DTO for content classification requests.
 * @property {string} content - The text content to classify.
 * @property {string[]} categories - A list of predefined categories to classify the content against.
 * @property {boolean} [allowMultiple=false] - Whether the content can belong to multiple categories.
 * @property {string} [modelId] - Optional: Specific model ID for classification.
 */
interface ContentClassificationRequestDto {
  content: string;
  categories: string[];
  allowMultiple?: boolean;
  modelId?: string;
}

/**
 * @interface ContentClassificationResponseDto
 * @description DTO for content classification responses.
 * @property {string | string[]} classification - The determined category or categories.
 * @property {Record<string, number>} [scores] - Optional: Confidence scores for each category.
 * @property {string} modelUsed - The model ID used for classification.
 */
interface ContentClassificationResponseDto {
  classification: string | string[];
  scores?: Record<string, number>;
  modelUsed: string;
}

/**
 * @interface SentimentAnalysisRequestDto
 * @description DTO for sentiment analysis requests.
 * @property {string} text - The text content to analyze for sentiment.
 * @property {'document' | 'sentence'} [granularity='document'] - Level of analysis.
 * @property {string} [modelId] - Optional: Specific model ID for sentiment analysis.
 */
interface SentimentAnalysisRequestDto {
  text: string;
  granularity?: 'document' | 'sentence';
  modelId?: string;
}

/**
 * @interface SentimentAnalysisResponseDto
 * @description DTO for sentiment analysis responses.
 * @property {'positive' | 'negative' | 'neutral' | string} sentiment - The overall sentiment detected.
 * @property {number} score - A numeric score representing sentiment intensity (e.g., -1 to 1, or 0 to 1 for positive).
 * @property {string} modelUsed - The model ID used for analysis.
 * @property {Array<{text: string; sentiment: string; score: number}>} [sentenceSentiments] - Optional: Sentiment for individual sentences if granularity is 'sentence'.
 */
interface SentimentAnalysisResponseDto {
  sentiment: 'positive' | 'negative' | 'neutral' | string; // Extensible string for more nuanced sentiments
  score: number; // e.g., -1 to 1, or provider-specific scale
  modelUsed: string;
  sentenceSentiments?: Array<{
    text: string;
    sentiment: 'positive' | 'negative' | 'neutral' | string;
    score: number;
  }>;
}


/**
 * @interface IUtilityLLMService
 * @description Defines the contract for a service that provides various LLM-powered utility functions.
 * This service abstracts the direct interaction with LLMs for common tasks like summarization,
 * translation, direct prompting, etc., allowing these utilities to be easily consumed by other parts
 * of the application or by these API routes.
 *
 * Implementations of this interface are expected to handle prompt engineering, model selection
 * (unless overridden by request), and interaction with the underlying LLM providers.
 */
export interface IUtilityLLMService {
  /**
   * Processes a direct, raw prompt against a configured LLM.
   * @async
   * @method processDirectPrompt
   * @param {DirectPromptRequestDto} request - The direct prompt request data.
   * @returns {Promise<DirectPromptResponseDto>} The LLM's response.
   * @throws {GMIError} If LLM interaction fails or input is invalid.
   */
  processDirectPrompt(request: DirectPromptRequestDto): Promise<DirectPromptResponseDto>;

  /**
   * Summarizes a given text.
   * @async
   * @method summarizeText
   * @param {SummarizationRequestDto} request - The summarization task request data.
   * @returns {Promise<SummarizationResponseDto>} The generated summary.
   * @throws {GMIError} If summarization fails.
   */
  summarizeText(request: SummarizationRequestDto): Promise<SummarizationResponseDto>;

  /**
   * Translates text from a source language to a target language.
   * @async
   * @method translateText
   * @param {TranslationRequestDto} request - The translation task request data.
   * @returns {Promise<TranslationResponseDto>} The translated text and detected source language.
   * @throws {GMIError} If translation fails.
   */
  translateText(request: TranslationRequestDto): Promise<TranslationResponseDto>;

  /**
   * Generates SEO-relevant keywords from a given piece of content.
   * @async
   * @method generateSeoKeywords
   * @param {SeoKeywordRequestDto} request - The SEO keyword generation request data.
   * @returns {Promise<SeoKeywordResponseDto>} An array of suggested keywords.
   * @throws {GMIError} If keyword generation fails.
   */
  generateSeoKeywords(request: SeoKeywordRequestDto): Promise<SeoKeywordResponseDto>;

  /**
   * Classifies a given piece of content into one or more predefined categories.
   * @async
   * @method classifyContent
   * @param {ContentClassificationRequestDto} request - The content classification request data.
   * @returns {Promise<ContentClassificationResponseDto>} The classification result(s) and confidence scores.
   * @throws {GMIError} If classification fails.
   */
  classifyContent(request: ContentClassificationRequestDto): Promise<ContentClassificationResponseDto>;

  /**
   * Analyzes the sentiment of a given piece of text.
   * @async
   * @method analyzeSentiment
   * @param {SentimentAnalysisRequestDto} request - The sentiment analysis request data.
   * @returns {Promise<SentimentAnalysisResponseDto>} The sentiment analysis result, including score and overall sentiment.
   * @throws {GMIError} If sentiment analysis fails.
   */
  analyzeSentiment(request: SentimentAnalysisRequestDto): Promise<SentimentAnalysisResponseDto>;
}


/**
 * Creates and configures the Express router for LLM-powered utility functions.
 * These routes provide general-purpose AI utilities like direct prompting, summarization,
 * translation, SEO keyword generation, content classification, and sentiment analysis.
 * All routes are protected by authentication by default.
 *
 * @function createUtilityLLMRoutes
 * @param {IUtilityLLMService} utilityLLMService - An instance of the service implementing `IUtilityLLMService`.
 * @param {IAuthService} authService - An instance of the authentication service for token validation.
 * @returns {Router} The configured Express router for utility LLM endpoints.
 */
export const createUtilityLLMRoutes = (utilityLLMService: IUtilityLLMService, authService: IAuthService): Router => {
  const router = Router();

  // Apply authentication middleware to all utility routes.
  // These utilities might involve LLM costs or process user-related data, justifying protection.
  router.use(authenticateToken(authService));

  /**
   * @route POST /api/v1/utility/direct-prompt
   * @description Sends a raw prompt directly to a configured LLM and returns the response.
   * This is a flexible endpoint for general-purpose LLM interactions.
   * @access Protected
   * @body {DirectPromptRequestDto} Requires `prompt`. Optional `context`, `modelId`, `completionOptions`.
   * @response {200} OK - Returns `DirectPromptResponseDto` with the LLM's generated text.
   * @response {400} Bad Request - If `prompt` is missing or input is malformed.
   * @response {500} Internal Server Error - If the LLM provider call fails or an unexpected error occurs.
   */
  router.post('/direct-prompt', async (req: AuthenticatedRequest, res: Response, next: NextFunction) => {
    try {
      const requestData = req.body as DirectPromptRequestDto;
      if (!requestData.prompt || typeof requestData.prompt !== 'string' || requestData.prompt.trim() === '') {
        return next(ErrorFactory.validation('A non-empty prompt string is required.', { field: 'prompt' }));
      }
      // Add more validation for completionOptions if necessary, e.g., ensuring temperature is within range.

      const result: DirectPromptResponseDto = await utilityLLMService.processDirectPrompt(requestData);
      return res.status(200).json(result);
    } catch (error) {
      // Errors from utilityLLMService should ideally be GMIError instances.
      return next(error);
    }
  });

  /**
   * @route POST /api/v1/utility/summarize
   * @description Generates a summary for a given text.
   * @access Protected
   * @body {SummarizationRequestDto} Requires `textToSummarize`. Optional `desiredLength`, `format`, `context`, `modelId`.
   * @response {200} OK - Returns `SummarizationResponseDto` with the generated `summary`.
   * @response {400} Bad Request - If `textToSummarize` is missing or input is malformed.
   * @response {500} Internal Server Error - If summarization fails.
   */
  router.post('/summarize', async (req: AuthenticatedRequest, res: Response, next: NextFunction) => {
    try {
      const requestData = req.body as SummarizationRequestDto;
      if (!requestData.textToSummarize || typeof requestData.textToSummarize !== 'string' || requestData.textToSummarize.trim() === '') {
        return next(ErrorFactory.validation('A non-empty textToSummarize string is required.', { field: 'textToSummarize' }));
      }
      // Validate other optional fields like desiredLength, format if they have specific constraints.

      const result: SummarizationResponseDto = await utilityLLMService.summarizeText(requestData);
      return res.status(200).json(result);
    } catch (error) {
      return next(error);
    }
  });

  /**
   * @route POST /api/v1/utility/translate
   * @description Translates a given text to a specified target language.
   * @access Protected
   * @body {TranslationRequestDto} Requires `textToTranslate` and `targetLanguage`. Optional `sourceLanguage`, `modelId`.
   * @response {200} OK - Returns `TranslationResponseDto` with `translatedText` and `detectedSourceLanguage`.
   * @response {400} Bad Request - If required fields are missing or languages are invalid.
   * @response {500} Internal Server Error - If translation fails.
   */
  router.post('/translate', async (req: AuthenticatedRequest, res: Response, next: NextFunction) => {
    try {
      const requestData = req.body as TranslationRequestDto;
      if (!requestData.textToTranslate || typeof requestData.textToTranslate !== 'string' || requestData.textToTranslate.trim() === '') {
        return next(ErrorFactory.validation('A non-empty textToTranslate string is required.', { field: 'textToTranslate' }));
      }
      if (!requestData.targetLanguage || typeof requestData.targetLanguage !== 'string' || requestData.targetLanguage.trim().length < 2) {
        return next(ErrorFactory.validation('A valid targetLanguage code (e.g., "es", "fr-CA") is required.', { field: 'targetLanguage' }));
      }
      // Optional: Validate sourceLanguage format if provided.

      const result: TranslationResponseDto = await utilityLLMService.translateText(requestData);
      return res.status(200).json(result);
    } catch (error) {
      return next(error);
    }
  });

  /**
   * @route POST /api/v1/utility/seo/keywords
   * @description Generates a list of SEO-relevant keywords from the provided content.
   * @access Protected
   * @body {SeoKeywordRequestDto} Requires `content`. Optional `maxKeywords`, `language`, `modelId`.
   * @response {200} OK - Returns `SeoKeywordResponseDto` with an array of `keywords`.
   * @response {400} Bad Request - If `content` is missing.
   * @response {500} Internal Server Error - If keyword generation fails.
   */
  router.post('/seo/keywords', async (req: AuthenticatedRequest, res: Response, next: NextFunction) => {
    try {
      const requestData = req.body as SeoKeywordRequestDto;
      if (!requestData.content || typeof requestData.content !== 'string' || requestData.content.trim() === '') {
        return next(ErrorFactory.validation('A non-empty content string is required for SEO keyword generation.', { field: 'content' }));
      }
      if (requestData.maxKeywords && (typeof requestData.maxKeywords !== 'number' || requestData.maxKeywords <= 0 || requestData.maxKeywords > 50)) {
        return next(ErrorFactory.validation('maxKeywords must be a positive number, typically not exceeding 50.', { field: 'maxKeywords' }));
      }

      const result: SeoKeywordResponseDto = await utilityLLMService.generateSeoKeywords(requestData);
      return res.status(200).json(result);
    } catch (error) {
      return next(error);
    }
  });

  /**
   * @route POST /api/v1/utility/classify
   * @description Classifies the provided content into one or more of the given categories.
   * @access Protected
   * @body {ContentClassificationRequestDto} Requires `content` and `categories` (array of strings). Optional `allowMultiple`, `modelId`.
   * @response {200} OK - Returns `ContentClassificationResponseDto` with `classification` (string or string[]) and optional `scores`.
   * @response {400} Bad Request - If `content` or `categories` are missing/invalid.
   * @response {500} Internal Server Error - If classification fails.
   */
  router.post('/classify', async (req: AuthenticatedRequest, res: Response, next: NextFunction) => {
    try {
      const requestData = req.body as ContentClassificationRequestDto;
      if (!requestData.content || typeof requestData.content !== 'string' || requestData.content.trim() === '') {
        return next(ErrorFactory.validation('A non-empty content string is required for classification.', { field: 'content' }));
      }
      if (!Array.isArray(requestData.categories) || requestData.categories.length === 0 || !requestData.categories.every(cat => typeof cat === 'string' && cat.trim() !== '')) {
        return next(ErrorFactory.validation('An array of non-empty category strings is required.', { field: 'categories' }));
      }

      const result: ContentClassificationResponseDto = await utilityLLMService.classifyContent(requestData);
      return res.status(200).json(result);
    } catch (error) {
      return next(error);
    }
  });

  /**
   * @route POST /api/v1/utility/sentiment
   * @description Analyzes the sentiment of the provided text.
   * @access Protected
   * @body {SentimentAnalysisRequestDto} Requires `text`. Optional `granularity`, `modelId`.
   * @response {200} OK - Returns `SentimentAnalysisResponseDto` with `sentiment`, `score`, and optional `sentenceSentiments`.
   * @response {400} Bad Request - If `text` is missing.
   * @response {500} Internal Server Error - If sentiment analysis fails.
   */
  router.post('/sentiment', async (req: AuthenticatedRequest, res: Response, next: NextFunction) => {
    try {
      const requestData = req.body as SentimentAnalysisRequestDto;
      if (!requestData.text || typeof requestData.text !== 'string' || requestData.text.trim() === '') {
        return next(ErrorFactory.validation('A non-empty text string is required for sentiment analysis.', { field: 'text' }));
      }

      const result: SentimentAnalysisResponseDto = await utilityLLMService.analyzeSentiment(requestData);
      return res.status(200).json(result);
    } catch (error) {
      return next(error);
    }
  });

  return router;
};